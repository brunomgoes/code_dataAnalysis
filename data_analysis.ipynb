{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "from tkinter import filedialog\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing, model_selection, pipeline, compose, linear_model, metrics, ensemble, neighbors, cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_roiFts = filedialog.askdirectory(title='Diretório dos arquivos de ROIs')\n",
    "path_microFts = filedialog.askdirectory(title='Diretório dos arquivos de MICROS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntar as tabelas de cada em imagem em uma única tabela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roiFts = []\n",
    "for file_name in os.listdir(path_roiFts):\n",
    "    file_path = os.path.join(path_roiFts, file_name)\n",
    "    file_open = open(file_path, \"r\")\n",
    "    df_file = pd.read_csv(file_open)\n",
    "\n",
    "    df_file['im_name'] = int(file_name[0:8])\n",
    "\n",
    "    df_roiFts.append(df_file)\n",
    "\n",
    "df_roiFts = pd.concat(df_roiFts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microFts = []\n",
    "for file_name in os.listdir(path_microFts):\n",
    "    file_path = os.path.join(path_microFts, file_name)\n",
    "    file_open = open(file_path, \"r\")\n",
    "    df_file = pd.read_csv(file_open)\n",
    "\n",
    "    df_file['im_name'] = int(file_name[0:8])\n",
    "\n",
    "    df_microFts.append(df_file)\n",
    "\n",
    "df_microFts = pd.concat(df_microFts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organização dos dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roiFts = df_roiFts.drop(labels=['Unnamed: 0'], axis=1)\n",
    "df_roiFts = df_roiFts.replace({True:1, False:0})\n",
    "df_roiFts['key'] = df_roiFts.apply(lambda row: f'{row[\"im_name\"]}_{row[\"roi_index\"]}', axis=1)\n",
    "\n",
    "df_roiFts.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_microFts = df_microFts.drop(labels=['Unnamed: 0'], axis=1)\n",
    "df_microFts['roi_index'] = pd.to_numeric(df_microFts['roi_index'], downcast='integer')\n",
    "df_microFts['im_name'] = pd.to_numeric(df_microFts['im_name'], downcast='integer')\n",
    "df_microFts['key'] = df_microFts.apply(lambda row: f'{row[\"im_name\"]}_{row[\"roi_index\"]}', axis=1)\n",
    "\n",
    "df_microFts.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultado do processamento de segmentação\n",
    "\n",
    "Resultados por imagem -> Número de ROIs detectados corretamente por imagem conforme ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_1 = df_roiFts.groupby(by='im_name')['roi_result'].value_counts()\n",
    "table_1 = table_1.unstack().fillna(value=0)\n",
    "table_1['Sensibilidade'] = table_1['True_positive']/(table_1['True_positive']+table_1['False_negative'])\n",
    "table_1['Precisao'] = table_1['True_positive']/(table_1['True_positive']+table_1['False_positive'])\n",
    "table_1['Acuracia'] = table_1['True_positive']/(table_1['True_positive']+table_1['False_negative']+table_1['False_positive'])\n",
    "\n",
    "table_1.style \\\n",
    "  .format(precision=0, thousands='.', decimal=',', na_rep=0) \\\n",
    "  .format(formatter='{:.1%}', thousands='.', decimal=',', subset=['Sensibilidade', 'Precisao', 'Acuracia']) \\\n",
    "  .relabel_index(['FN', 'FP', 'TP', 'Sensib.', 'Precisão', 'Acurácia'], axis=1) \\\n",
    "  .highlight_between(subset=['Sensibilidade', 'Precisao', 'Acuracia'], color='green', left=0.75, right=1) \\\n",
    "  .highlight_between(subset='Sensibilidade', color='red', left=0, right=0.40) \\\n",
    "  .highlight_between(subset=['Precisao', 'Acuracia'], color='red', left=0, right=0.1) \\\n",
    "  .highlight_between(subset=['Precisao', 'Acuracia'], color='green', left=0.20, right=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Média e Desvio Padrão dos resultados de todas as imagens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_2 = pd.DataFrame([table_1.mean(), table_1.std()], index=['mean', 'std']).T\n",
    "\n",
    "table_2.style \\\n",
    "    .format(precision=2, thousands='.', decimal=',') \\\n",
    "    .format(formatter='{:.2%}', thousands='.', decimal=',', subset=pd.IndexSlice[['Sensibilidade', 'Precisao', 'Acuracia'], :]) \\\n",
    "    .relabel_index(labels=['Mean', 'STD'], axis=1) \\\n",
    "    .relabel_index(labels=['Mean', 'STD'], axis=1).relabel_index(labels=['FN', 'FP', 'TP', 'Sensib.', 'Precisão', 'Acurácia'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisão do total de imagens em 2 partes para compor o set de TESTE e de TREINAMENTO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train, img_test = model_selection.train_test_split(df_roiFts['im_name'].unique(), test_size=0.35, train_size=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar o dataframe de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_train = df_roiFts.loc[df_roiFts['im_name'].isin(img_train)]\n",
    "\n",
    "micro_train = df_microFts.loc[df_microFts['key'].isin(roi_train['key'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinação de atributos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Média e desvio padrão dos atributos de textura\n",
    "roi_train.loc[:, 't_ASM_mean'] = roi_train.loc[:, ['t_ASM_0', 't_ASM_90', 't_ASM_180', 't_ASM_270']].mean(axis=1)\n",
    "roi_train.loc[:, 't_ASM_std'] = roi_train.loc[:, ['t_ASM_0', 't_ASM_90', 't_ASM_180', 't_ASM_270']].std(axis=1)\n",
    "roi_train.loc[:, 't_contrast_mean'] = roi_train.loc[:, ['t_contrast_0', 't_contrast_90', 't_contrast_180', 't_contrast_270']].mean(axis=1)\n",
    "roi_train.loc[:, 't_contrast_std'] = roi_train.loc[:, ['t_contrast_0', 't_contrast_90', 't_contrast_180', 't_contrast_270']].std(axis=1)\n",
    "roi_train.loc[:, 't_correlation_mean'] = roi_train.loc[:, ['t_correlation_0', 't_correlation_90', 't_correlation_180', 't_correlation_270']].mean(axis=1)\n",
    "roi_train.loc[:, 't_correlation_std'] = roi_train.loc[:, ['t_correlation_0', 't_correlation_90', 't_correlation_180', 't_correlation_270']].std(axis=1)\n",
    "roi_train.loc[:, 't_sumSqrVariance_mean'] = roi_train.loc[:, ['t_sumSqrVariance_0', 't_sumSqrVariance_90', 't_sumSqrVariance_180', 't_sumSqrVariance_270']].mean(axis=1)\n",
    "roi_train.loc[:, 't_sumSqrVariance_std'] = roi_train.loc[:, ['t_sumSqrVariance_0', 't_sumSqrVariance_90', 't_sumSqrVariance_180', 't_sumSqrVariance_270']].std(axis=1)\n",
    "roi_train.loc[:, 't_idm_mean'] = roi_train.loc[:, ['t_idm_0', 't_idm_90', 't_idm_180', 't_idm_270']].mean(axis=1)\n",
    "roi_train.loc[:, 't_idm_std'] = roi_train.loc[:, ['t_idm_0', 't_idm_90', 't_idm_180', 't_idm_270']].std(axis=1)\n",
    "roi_train.loc[:, 't_sumAverage_mean'] = roi_train.loc[:, ['t_sumAverage_0', 't_sumAverage_90', 't_sumAverage_180', 't_sumAverage_270']].mean(axis=1)\n",
    "roi_train.loc[:, 't_sumAverage_std'] = roi_train.loc[:, ['t_sumAverage_0', 't_sumAverage_90', 't_sumAverage_180', 't_sumAverage_270']].std(axis=1)\n",
    "roi_train.loc[:, 't_sumVariance_mean'] = roi_train.loc[:, ['t_sumVariance_0', 't_sumVariance_90', 't_sumVariance_180', 't_sumVariance_270']].mean(axis=1)\n",
    "roi_train.loc[:, 't_sumVariance_std'] = roi_train.loc[:, ['t_sumVariance_0', 't_sumVariance_90', 't_sumVariance_180', 't_sumVariance_270']].std(axis=1)\n",
    "roi_train.loc[:, 't_sumEntropy_mean'] = roi_train.loc[:, ['t_sumEntropy_0', 't_sumEntropy_90', 't_sumEntropy_180', 't_sumEntropy_270']].mean(axis=1)\n",
    "roi_train.loc[:, 't_sumEntropy_std'] = roi_train.loc[:, ['t_sumEntropy_0', 't_sumEntropy_90', 't_sumEntropy_180', 't_sumEntropy_270']].std(axis=1)\n",
    "roi_train.loc[:, 't_IMC2_mean'] = roi_train.loc[:, ['t_entropy_0', 't_entropy_90', 't_entropy_180', 't_entropy_270']].mean(axis=1)\n",
    "roi_train.loc[:, 't_entropy_std'] = roi_train.loc[:, ['t_entropy_0', 't_entropy_90', 't_entropy_180', 't_entropy_270']].std(axis=1)\n",
    "roi_train.loc[:, 't_diffVariance_mean'] = roi_train.loc[:, ['t_diffVariance_0', 't_diffVariance_90', 't_diffVariance_180', 't_diffVariance_270']].mean(axis=1)\n",
    "roi_train.loc[:, 't_diffVariance_std'] = roi_train.loc[:, ['t_diffVariance_0', 't_diffVariance_90', 't_diffVariance_180', 't_diffVariance_270']].std(axis=1)\n",
    "roi_train.loc[:, 't_diffEntropy_mean'] = roi_train.loc[:, ['t_diffEntropy_0', 't_diffEntropy_90', 't_diffEntropy_180', 't_diffEntropy_270']].mean(axis=1)\n",
    "roi_train.loc[:, 't_diffEntropy_std'] = roi_train.loc[:, ['t_diffEntropy_0', 't_diffEntropy_90', 't_diffEntropy_180', 't_diffEntropy_270']].std(axis=1)\n",
    "roi_train.loc[:, 't_IMC1_mean'] = roi_train.loc[:, ['t_IMC1_0', 't_IMC1_90', 't_IMC1_180', 't_IMC1_270']].mean(axis=1)\n",
    "roi_train.loc[:, 't_IMC1_std'] = roi_train.loc[:, ['t_IMC1_0', 't_IMC1_90', 't_IMC1_180', 't_IMC1_270']].std(axis=1)\n",
    "roi_train.loc[:, 't_IMC2_mean'] = roi_train.loc[:, ['t_IMC2_0', 't_IMC2_90', 't_IMC2_180', 't_IMC2_270']].mean(axis=1)\n",
    "roi_train.loc[:, 't_IMC2_std'] = roi_train.loc[:, ['t_IMC2_0', 't_IMC2_90', 't_IMC2_180', 't_IMC2_270']].std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Média dos itens correspondentes em micro_train\n",
    "mean_values = micro_train.iloc[:,1:].groupby('key').mean()\n",
    "mean_values.columns = ['obj_'+col for col in mean_values.columns]\n",
    "\n",
    "roi_train = pd.merge(roi_train, mean_values, on='key', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos não numéricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_att = ['roi_index', 'roi_result', 'roi_target', 'im_name', 'key', ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise do dataframe de treinamento\n",
    "### Histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in roi_train.iloc[:, 3:-2]:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(roi_train[col], bins=100, density=False, histtype='step', log=False, color='blue')\n",
    "    ax.hist(roi_train.loc[roi_train['roi_result'] == 'False_negative', col], bins=100, density=False, histtype='step', log=False, color='purple')\n",
    "    ax.hist(roi_train.loc[roi_train['roi_result'] == 'False_positive', col], bins=100, density=False, histtype='step', log=False, color='red')\n",
    "    ax.hist(roi_train.loc[roi_train['roi_result'] == 'True_positive', col], bins=100, density=False, histtype='step', log=False, color='green')\n",
    "    plt.grid(True)\n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in roi_train.iloc[:, 3:-2]:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(20,10))\n",
    "    ax[0].boxplot(roi_train.loc[roi_train['roi_result'] == 'False_negative', col], notch=True)\n",
    "    ax[0].set_title('Falso negativo')\n",
    "    ax[0].grid(True)\n",
    "    ax[1].boxplot(roi_train.loc[roi_train['roi_result'] == 'False_positive', col], notch=True)\n",
    "    ax[1].set_title('Falso positivo')\n",
    "    ax[1].grid(True)\n",
    "    ax[2].boxplot(roi_train.loc[roi_train['roi_result'] == 'True_positive', col], notch=True)\n",
    "    ax[2].set_title('Verdadeiro Positivo')\n",
    "    ax[2].grid(True)\n",
    "    plt.suptitle(col)\n",
    "    plt.show()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancear dataframe de treinamento -> Igualar o número de alvos True e False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([\n",
    "    roi_train.loc[roi_train['roi_result']=='True_positive', :],\n",
    "    roi_train.loc[roi_train['roi_result']=='False_positive', :].sample(roi_train.loc[roi_train['roi_result']=='True_positive', :].shape[0], random_state=985)\n",
    "])\n",
    "df_train[['roi_result', 'roi_target']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento do dataframe\n",
    "\n",
    "### Histogramas do dataframe de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.loc[:, ~df_train.columns.isin(non_att)]:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(df_train[col], bins=100, density=False, histtype='step', log=False, color='blue')\n",
    "    plt.grid(True)\n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots do dataframe de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.iloc[:, 3:-2]:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(df_train[col], vert=False)\n",
    "    plt.grid(True)\n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline para pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Criar pipelines específicas conforme necessidade dos dados\n",
    "base_pipeline = pipeline.make_pipeline(\n",
    "    preprocessing.MinMaxScaler()\n",
    ")\n",
    "\n",
    "###### Operador para aplicar cada pipeline na coluna específica\n",
    "p_processing = compose.ColumnTransformer([\n",
    "    ('base', base_pipeline, compose.make_column_selector(dtype_include=np.number))\n",
    "], remainder='passthrough')\n",
    "\n",
    "df_train_scaled = df_train.copy()\n",
    "##### aplicar os operadores no dataframe\n",
    "df_train_scaled.loc[:, ~df_train_scaled.columns.isin(non_att)] = p_processing.fit_transform(df_train_scaled.loc[:, ~df_train_scaled.columns.isin(non_att)])\n",
    "col_labels = p_processing.get_feature_names_out() ###### nome das variáveis/características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlação entre variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_train_scaled.iloc[:,2:].corr()\n",
    "corr_matrix['roi_target'].sort_values(ascending=False) ### Correlação entre as variáveis e o resultado esperado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecionando variáveis pelo valor da correlação com o resultado esperado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts_pos = corr_matrix['roi_target'].sort_values(ascending=False) >= 0.2\n",
    "fts_neg = corr_matrix['roi_target'].sort_values(ascending=False) <= -0.2\n",
    "\n",
    "slc_fts = np.array(corr_matrix[np.logical_and(np.logical_or(fts_pos, fts_neg), corr_matrix['roi_target'].sort_values(ascending=False) != 1.0)].index)\n",
    "slc_fts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = neighbors.KNeighborsClassifier(\n",
    "    n_neighbors=15,\n",
    "    weights='distance', ### ['uniform', 'distance']\n",
    "    algorithm='kd_tree', ### ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    p=1, ### power parameter for minkowski metric -> 1 é manhattan_distance e 2 é euclidean distance\n",
    "    metric='minkowski' ### metric to use for distance computation -> ['euclidean', 'cosine', 'chebyshev', 'correlation', 'manhattan', 'minkowski']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(\n",
    "    n_neighbors=[2, 5, 7, 10, 15, 20, 25, 30],\n",
    "    weights=['uniform', 'distance'],\n",
    "    algorithm=['ball_tree', 'kd_tree', 'brute'],\n",
    "    leaf_size=[5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "    p=[1, 2],\n",
    "    metric=['eucliedean', 'cosine', 'manhattan', 'minkowski']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = model_selection.GridSearchCV(model_knn, param_grid, cv=10, scoring='accuracy')\n",
    "grid_search.fit(df_train.loc[:, slc_fts], df_train['roi_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Primeiras 5 combinações com melhores resultados\n",
    "cv_res = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "cv_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dstb = dict(\n",
    "    n_neighbors=stats.randint(low=1, high=100),\n",
    "    weights=['uniform', 'distance'],\n",
    "    algorithm=['ball_tree', 'kd_tree', 'brute'],\n",
    "    leaf_size=stats.randint(low=1, high=100),\n",
    "    p=[1, 2],\n",
    "    metric=['eucliedean', 'manhattan', 'minkowski']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search = model_selection.RandomizedSearchCV(model_knn, param_distributions=param_dstb, n_iter=1000, cv=10, scoring='accuracy')\n",
    "rnd_search.fit(df_train.loc[:, slc_fts], df_train['roi_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Primeiras 5 combinações com melhores resultados\n",
    "cv_res = pd.DataFrame(rnd_search.cv_results_)\n",
    "cv_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "cv_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn.fit(df_train.loc[:, slc_fts], df_train['roi_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = model_selection.cross_val_score(model_knn, df_train.loc[:, slc_fts], df_train['roi_target'], cv=10, scoring='accuracy')\n",
    "\n",
    "y_train_pred = model_selection.cross_val_predict(model_knn, df_train.loc[:, slc_fts], df_train['roi_target'], cv=10, method='predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics.ConfusionMatrixDisplay.from_predictions(df_train['roi_target'], y_train_pred, normalize='true', values_format='.2%')\n",
    "plt.show()\n",
    "\n",
    "print('\\nRecall score: ', '{:.2%}'.format(metrics.recall_score(df_train['roi_target'], y_train_pred)))\n",
    "print('Precision score: ', '{:.2%}'.format(metrics.precision_score(df_train['roi_target'], y_train_pred)))\n",
    "print('Accuracy: ', '{:.2%}'.format(metrics.accuracy_score(df_train['roi_target'], y_train_pred)))\n",
    "print('F1-score: ', metrics.f1_score(df_train['roi_target'], y_train_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisão vs Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds = metrics.precision_recall_curve(df_train['roi_target'], y_train_pred)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "plt.xlabel('Threshold')\n",
    "plt.legend(loc='center right')\n",
    "plt.grid(visible=True)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(recalls, precisions, linewidth=2, label=\"Precision/Recall curve\")\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.grid(visible=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, roc_thresh = metrics.roc_curve(df_train['roi_target'], y_train_pred)\n",
    "\n",
    "print('ROC Area Under Curve: ', metrics.roc_auc_score(df_train['roi_target'], y_train_pred))\n",
    "\n",
    "plt.plot(fpr, tpr, linewidth=2, label=\"ROC curve\")\n",
    "plt.plot([0, 1], [0, 1], 'k:', label=\"ROC curve\")\n",
    "plt.grid(visible=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "#### Montando a rede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorando hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "######### Definindo os hiperparametros\n",
    "    n_hidden = hp.Int('n_hidden', min_value=0, max_value=4, default=2)\n",
    "    n_neurons = hp.Int('n_neurons', min_value=16, max_value=100)\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "    optimizer = hp.Choice('optimizer', values=['sgd', 'adam'])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    ####### Montando o modelo\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=[21], batch_size=32))\n",
    "    for i in range(n_hidden): ###### camadas intermediárias\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation='sigmoid'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    ###### Compilando o modelo\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_tuner = kt.RandomSearch(build_model,\n",
    "                                    objective='val_accuracy',\n",
    "                                    max_trials=15,\n",
    "                                    overwrite=True,\n",
    "                                    seed=654, #### random seed\n",
    "                                    project_name='roi_classification'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Salvar o modelo conforme o checkpoint definido\n",
    "cb_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='checkpoint_file.keras',\n",
    "    monitor='val_accuracy', ### 'val_loss',\n",
    "    verbose=False,\n",
    "    save_best_only=True,\n",
    "    mode='auto',\n",
    ")\n",
    "\n",
    "#### Interromper o treinamento conforme critérios estabelecidos\n",
    "cb_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=100,\n",
    "    verbose=False,\n",
    "    mode='auto',\n",
    "    start_from_epoch=0,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "#### TensorBoard\n",
    "cb_tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='logs',\n",
    "    profile_batch=(100,200)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_scaled.loc[:, slc_fts]\n",
    "y_train = df_train_scaled['roi_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_tuner.search(X_train, y_train, epochs=5000, validation_split=0.25, batch_size=32, shuffle=True,\n",
    "                           callbacks=[cb_checkpoint, cb_early_stopping, cb_tensorboard], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = random_search_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "best_trial.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste e Avaliação"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
